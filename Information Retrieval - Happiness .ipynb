{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import time\n",
    "import string\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 List the Files in the specific directory (Section 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listFile(d):    \n",
    "    path = [os.path.abspath(os.path.join(d,i)) for i in os.listdir(d)]\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Read the file and return the content (Section 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(d):\n",
    "    file = open(d,\"r\",encoding='utf-8')\n",
    "    content = file.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create token (Section 1)\n",
    "- input (content, document id)\n",
    "- output (pairs of token and document id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createToken(content, d):\n",
    "    did = os.path.basename(d).replace(\".txt\",\"\")\n",
    "    tokens = list()\n",
    "    tokenizer = WhitespaceTokenizer()\n",
    "    for t in tokenizer.tokenize(content):\n",
    "        tokens = tokens + [[t,did]]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linguistic (lower, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linguisticToken(token_list):\n",
    "    #stemmer = PorterStemmer() #stem\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    tokens = list()\n",
    "    for [t,d] in token_list:\n",
    "        token = t.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "        if token == '': #if the token is only punctuation\n",
    "            continue\n",
    "        token = token.lower()\n",
    "        #token = stemmer.stem(token)\n",
    "        token = lemmer.lemmatize(token)\n",
    "        tokens += [[token,d]]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortToken(token_list):\n",
    "    token_list.sort(key=lambda e: (e[0],e[1]))\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Transform in posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformPosting(sorted_list):\n",
    "    postDictionary = {}\n",
    "    for term,docId in sorted_list:\n",
    "        postDictionary.setdefault(term,[]).append(docId)\n",
    "    for key in postDictionary:\n",
    "        post = list(dict.fromkeys(postDictionary[key]))\n",
    "        post.sort(key=int)\n",
    "        postDictionary[key] = (len(post),post)\n",
    "    return postDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Merge the Postings (Intersecting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergePostings(postingList):\n",
    "    posting1 = postingList[0]\n",
    "    #print(posting2)\n",
    "    \n",
    "    for i in range(1,len(postingList),1):\n",
    "        merged = []\n",
    "        posting2 = postingList[i]\n",
    "        #print(posting1[0])\n",
    "        p = 0\n",
    "        q = 0\n",
    "        #print(len(posting2))\n",
    "        while p < len(posting1) and q < len(posting2):\n",
    "            if int(posting1[p]) == int(posting2[q]):\n",
    "                merged.append(posting1[p])\n",
    "                \n",
    "                #print(p,q,posting1[p],posting2[q])\n",
    "                p += 1\n",
    "                q += 1\n",
    "            elif int(posting1[p]) < int(posting2[q]):\n",
    "                \n",
    "                #print(p,q,posting1[p],posting2[q])\n",
    "                p += 1\n",
    "            else:\n",
    "                \n",
    "                #print(p,q,posting1[p],posting2[q])\n",
    "                q += 1\n",
    "        posting1 = merged\n",
    "        #print(p,q)\n",
    "        #print(merged)\n",
    "    return posting1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index (Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to index:  101.583\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "files = listFile(\"HillaryEmails\") #list dir\n",
    "tokens = list()\n",
    "for docs in files:\n",
    "    file_content = readFile(docs) #read content\n",
    "    token = createToken(file_content,docs) #create token\n",
    "    token = linguisticToken(token) #stemming\n",
    "    tokens += token\n",
    "tokens = sortToken(tokens) #token from all files\n",
    "posting = transformPosting(tokens) #create posting from these files\n",
    "\n",
    "end_time = time.time()\n",
    "time_to_index = end_time - start_time\n",
    "print(\"Time taken to index: \" , round(time_to_index,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    q_token = createToken(query)\n",
    "    operator = [i for i in q_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = pd.DataFrame(posting) # check the reverse index\n",
    "#t = t.T\n",
    "#t.to_csv(\"posting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72052, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rushat</th>\n",
       "      <td>1</td>\n",
       "      <td>[5961]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152010</th>\n",
       "      <td>1</td>\n",
       "      <td>[5587]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locate</th>\n",
       "      <td>17</td>\n",
       "      <td>[10, 12, 21, 26, 1734, 2815, 3738, 4332, 4582,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c05772256</th>\n",
       "      <td>1</td>\n",
       "      <td>[6471]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lanny</th>\n",
       "      <td>15</td>\n",
       "      <td>[512, 513, 591, 1402, 1875, 2144, 2151, 2805, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flux</th>\n",
       "      <td>1</td>\n",
       "      <td>[6755]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haaretzherald</th>\n",
       "      <td>1</td>\n",
       "      <td>[5789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substantively</th>\n",
       "      <td>13</td>\n",
       "      <td>[525, 526, 527, 528, 2400, 2401, 2402, 3521, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etonian</th>\n",
       "      <td>8</td>\n",
       "      <td>[1066, 1175, 1176, 3252, 3506, 3509, 3643, 3644]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171126</th>\n",
       "      <td>2</td>\n",
       "      <td>[6054, 6971]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allnighters</th>\n",
       "      <td>2</td>\n",
       "      <td>[5434, 5436]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>progay</th>\n",
       "      <td>6</td>\n",
       "      <td>[1696, 2085, 2087, 3623, 3624, 5050]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>•arturo</th>\n",
       "      <td>2</td>\n",
       "      <td>[967, 2709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c05774620</th>\n",
       "      <td>1</td>\n",
       "      <td>[7280]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>2129</td>\n",
       "      <td>[7, 9, 11, 14, 16, 32, 36, 43, 45, 47, 49, 51,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>073118</th>\n",
       "      <td>2</td>\n",
       "      <td>[5536, 7337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c05772695</th>\n",
       "      <td>1</td>\n",
       "      <td>[6651]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c05765992</th>\n",
       "      <td>1</td>\n",
       "      <td>[3409]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pours</th>\n",
       "      <td>1</td>\n",
       "      <td>[5288]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relate</th>\n",
       "      <td>39</td>\n",
       "      <td>[64, 241, 259, 1583, 1605, 2590, 3644, 3988, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ungrounded</th>\n",
       "      <td>1</td>\n",
       "      <td>[7084]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225245</th>\n",
       "      <td>1</td>\n",
       "      <td>[2277]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade</th>\n",
       "      <td>214</td>\n",
       "      <td>[10, 12, 21, 26, 43, 58, 62, 80, 83, 95, 144, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shaban</th>\n",
       "      <td>5</td>\n",
       "      <td>[177, 178, 179, 180, 7917]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c05770565</th>\n",
       "      <td>1</td>\n",
       "      <td>[5640]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>der</th>\n",
       "      <td>9</td>\n",
       "      <td>[1772, 2642, 4794, 6275, 6307, 6308, 6316, 631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual</th>\n",
       "      <td>4</td>\n",
       "      <td>[1670, 5843, 6272, 7396]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statescb0045358</th>\n",
       "      <td>1</td>\n",
       "      <td>[112]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workplanning</th>\n",
       "      <td>1</td>\n",
       "      <td>[3469]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10h</th>\n",
       "      <td>1</td>\n",
       "      <td>[6182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>establishment</th>\n",
       "      <td>78</td>\n",
       "      <td>[2, 5, 8, 76, 681, 1052, 1056, 1132, 1176, 119...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seng</th>\n",
       "      <td>1</td>\n",
       "      <td>[6037]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valdes</th>\n",
       "      <td>1</td>\n",
       "      <td>[4034]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gelber</th>\n",
       "      <td>7</td>\n",
       "      <td>[4696, 4698, 6295, 6425, 6428, 6434, 7417]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>governmentcivil</th>\n",
       "      <td>2</td>\n",
       "      <td>[920, 3130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218400</th>\n",
       "      <td>1</td>\n",
       "      <td>[1923]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026470724</th>\n",
       "      <td>1</td>\n",
       "      <td>[3705]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsa</th>\n",
       "      <td>2</td>\n",
       "      <td>[461, 1724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aitdtikes11</th>\n",
       "      <td>1</td>\n",
       "      <td>[1749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanfranciscochronicle</th>\n",
       "      <td>1</td>\n",
       "      <td>[5279]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>termed</th>\n",
       "      <td>2</td>\n",
       "      <td>[6888, 6907]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mental</th>\n",
       "      <td>17</td>\n",
       "      <td>[1861, 2348, 3144, 3193, 3573, 5123, 5179, 543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restez</th>\n",
       "      <td>1</td>\n",
       "      <td>[2531]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>georgiaea</th>\n",
       "      <td>1</td>\n",
       "      <td>[5789]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eebtppbta</th>\n",
       "      <td>2</td>\n",
       "      <td>[919, 3130]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>containment</th>\n",
       "      <td>18</td>\n",
       "      <td>[98, 135, 136, 140, 143, 430, 1175, 1693, 1873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomlinson</th>\n",
       "      <td>6</td>\n",
       "      <td>[111, 5213, 5216, 7039, 7889, 7909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nominated</th>\n",
       "      <td>28</td>\n",
       "      <td>[209, 210, 239, 240, 719, 967, 1389, 1397, 145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perversity</th>\n",
       "      <td>2</td>\n",
       "      <td>[5500, 5501]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thencandidate</th>\n",
       "      <td>1</td>\n",
       "      <td>[1638]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                                                  1\n",
       "rushat                    1                                             [5961]\n",
       "152010                    1                                             [5587]\n",
       "locate                   17  [10, 12, 21, 26, 1734, 2815, 3738, 4332, 4582,...\n",
       "c05772256                 1                                             [6471]\n",
       "lanny                    15  [512, 513, 591, 1402, 1875, 2144, 2151, 2805, ...\n",
       "flux                      1                                             [6755]\n",
       "haaretzherald             1                                             [5789]\n",
       "substantively            13  [525, 526, 527, 528, 2400, 2401, 2402, 3521, 4...\n",
       "etonian                   8   [1066, 1175, 1176, 3252, 3506, 3509, 3643, 3644]\n",
       "171126                    2                                       [6054, 6971]\n",
       "allnighters               2                                       [5434, 5436]\n",
       "progay                    6               [1696, 2085, 2087, 3623, 3624, 5050]\n",
       "•arturo                   2                                        [967, 2709]\n",
       "c05774620                 1                                             [7280]\n",
       "would                  2129  [7, 9, 11, 14, 16, 32, 36, 43, 45, 47, 49, 51,...\n",
       "073118                    2                                       [5536, 7337]\n",
       "c05772695                 1                                             [6651]\n",
       "c05765992                 1                                             [3409]\n",
       "pours                     1                                             [5288]\n",
       "relate                   39  [64, 241, 259, 1583, 1605, 2590, 3644, 3988, 3...\n",
       "ungrounded                1                                             [7084]\n",
       "225245                    1                                             [2277]\n",
       "trade                   214  [10, 12, 21, 26, 43, 58, 62, 80, 83, 95, 144, ...\n",
       "shaban                    5                         [177, 178, 179, 180, 7917]\n",
       "c05770565                 1                                             [5640]\n",
       "der                       9  [1772, 2642, 4794, 6275, 6307, 6308, 6316, 631...\n",
       "residual                  4                           [1670, 5843, 6272, 7396]\n",
       "statescb0045358           1                                              [112]\n",
       "workplanning              1                                             [3469]\n",
       "10h                       1                                             [6182]\n",
       "establishment            78  [2, 5, 8, 76, 681, 1052, 1056, 1132, 1176, 119...\n",
       "seng                      1                                             [6037]\n",
       "valdes                    1                                             [4034]\n",
       "gelber                    7         [4696, 4698, 6295, 6425, 6428, 6434, 7417]\n",
       "governmentcivil           2                                        [920, 3130]\n",
       "218400                    1                                             [1923]\n",
       "2026470724                1                                             [3705]\n",
       "fsa                       2                                        [461, 1724]\n",
       "aitdtikes11               1                                             [1749]\n",
       "sanfranciscochronicle     1                                             [5279]\n",
       "termed                    2                                       [6888, 6907]\n",
       "mental                   17  [1861, 2348, 3144, 3193, 3573, 5123, 5179, 543...\n",
       "restez                    1                                             [2531]\n",
       "georgiaea                 1                                             [5789]\n",
       "eebtppbta                 2                                        [919, 3130]\n",
       "containment              18  [98, 135, 136, 140, 143, 430, 1175, 1693, 1873...\n",
       "tomlinson                 6                [111, 5213, 5216, 7039, 7889, 7909]\n",
       "nominated                28  [209, 210, 239, 240, 719, 967, 1389, 1397, 145...\n",
       "perversity                2                                       [5500, 5501]\n",
       "thencandidate             1                                             [1638]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canton\n",
      "obama\n"
     ]
    }
   ],
   "source": [
    "\n",
    "searchA = linguisticToken([['canton','']])[0][0]\n",
    "searchB = linguisticToken([['obama','']])[0][0]\n",
    "print(searchA)\n",
    "print(searchB)\n",
    "#print(posting[searchA][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['152', '6073', '6079']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = mergePostings([posting[searchA][1],posting[searchB][1]])\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergePostings1([['969', '1628', '1645', '1893', '1943', '2472', '3154', '5107', '5490', '5843', '5922', '7081', '7479'],\n",
    "              ['10', '12', '21', '23', '24', '26', '32', '43', '81', '86', '98', '128', '131', '134', '135', '139', '140', '143', '163', '168', '175', '204', '215', '266', '267', '269', '290', '300', '328', '389', '390', '443', '460', '462', '493', '591', '697', '733', '772', '795', '797', '798', '802', '885', '918', '921', '953', '954', '965', '966', '969', '979', '980', '982', '997', '1004', '1052', '1056', '1066', '1082', '1097', '1119', '1190', '1198', '1199', '1200', '1233', '1294', '1299', '1359', '1360', '1408', '1412', '1459', '1472', '1474', '1485', '1563', '1601', '1602', '1607', '1615', '1639', '1688', '1745', '1760', '1797', '1815', '1816', '1860', '1861', '1921', '1922', '1941', '1996', '2051', '2060', '2064', '2065', '2119', '2165', '2170', '2172', '2200', '2203', '2213', '2228', '2247', '2277', '2348', '2394', '2449', '2474', '2479', '2482', '2532', '2565', '2604', '2647', '2648', '2700', '2701', '2704', '2755', '2758', '2764', '2781', '2805', '2864', '2868', '2875', '2894', '2933', '2940', '2942', '2948', '2978', '2979', '3014', '3054', '3055', '3152', '3153', '3154', '3165', '3166', '3169', '3170', '3171', '3178', '3193', '3209', '3217', '3252', '3268', '3273', '3274', '3301', '3392', '3394', '3430', '3452', '3472', '3478', '3479', '3497', '3498', '3499', '3502', '3567', '3568', '3571', '3593', '3606', '3615', '3640', '3655', '3688', '3692', '3693', '3695', '3696', '3709', '3710', '3720', '3738', '3740', '3742', '3755', '3769', '3771', '3802', '3839', '3849', '3884', '3892', '3913', '3948', '3949', '3995', '4040', '4044', '4045', '4060', '4065', '4119', '4120', '4141', '4144', '4145', '4146', '4163', '4171', '4181', '4232', '4233', '4264', '4276', '4292', '4304', '4320', '4332', '4334', '4354', '4394', '4399', '4405', '4408', '4416', '4428', '4429', '4459', '4467', '4489', '4510', '4511', '4514', '4547', '4558', '4591', '4597', '4599', '4616', '4632', '4639', '4653', '4663', '4666', '4669', '4694', '4697', '4700', '4701', '4704', '4708', '4712', '4767', '4794', '4875', '4899', '4900', '4906', '4953', '4968', '4969', '4971', '5031', '5032', '5036', '5037', '5098', '5102', '5106', '5107', '5115', '5116', '5133', '5162', '5164', '5168', '5172', '5175', '5208', '5211', '5212', '5217', '5219', '5236', '5237', '5238', '5248', '5264', '5279', '5287', '5288', '5300', '5402', '5412', '5413', '5433', '5434', '5436', '5452', '5490', '5538', '5585', '5595', '5599', '5600', '5602', '5609', '5627', '5642', '5646', '5648', '5653', '5669', '5676', '5677', '5685', '5715', '5719', '5721', '5788', '5789', '5806', '5879', '5880', '5897', '5900', '5901', '5928', '5945', '5979', '5982', '5991', '5998', '5999', '6006', '6009', '6011', '6021', '6037', '6054', '6058', '6069', '6112', '6182', '6210', '6258', '6270', '6280', '6283', '6308', '6335', '6377', '6387', '6439', '6443', '6479', '6480', '6487', '6495', '6499', '6500', '6504', '6507', '6514', '6528', '6539', '6568', '6570', '6574', '6602', '6627', '6634', '6635', '6637', '6638', '6649', '6650', '6685', '6699', '6707', '6708', '6716', '6718', '6751', '6759', '6764', '6769', '6801', '6808', '6834', '6888', '6907', '6916', '6924', '6971', '6974', '7031', '7036', '7038', '7041', '7042', '7073', '7080', '7085', '7087', '7100', '7117', '7119', '7134', '7162', '7165', '7245', '7257', '7271', '7278', '7279', '7280', '7339', '7345', '7359', '7378', '7394', '7398', '7403', '7407', '7410', '7423', '7453', '7455', '7457', '7458', '7459', '7460', '7465', '7474', '7501', '7503', '7504', '7569', '7570', '7571', '7576', '7577', '7582', '7584', '7608', '7645', '7686', '7691', '7699', '7705', '7728', '7761', '7767', '7769', '7796', '7846', '7880', '7907', '7909', '7929', '7940', '7943'],\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2621544"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(posting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
